{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from source.preprocessing import splitter, converter\n",
    "from source.datamodels import iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1 Preprocessing\n",
    "load datasets, convert third-party data files to our format etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.1 Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "project_folder = \"F:/PythonNotebooks/Study/Quantum/Bearings/\"\n",
    "own_data_path = os.path.join(project_folder, \"data/own datasets/\")\n",
    "third_party_data_path = os.path.join(project_folder, \"data/third party datasets/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.1.1 Load our initial datasets\n",
    "Datasets obtained from our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "signals_dataset = pd.read_csv(os.path.join(own_data_path, 'bearing_signals.csv'))\n",
    "classes_dataset = pd.read_csv(os.path.join(own_data_path, 'bearing_classes.csv'), delimiter=';', skiprows=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.2 Load our joined datasets\n",
    "Datasets obtained from our experiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "full_dataset = pd.read_csv(os.path.join(own_data_path, 'bearings.csv'), delimiter=';', skiprows=[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.1.3 Third-party datasets\n",
    "Load converted third-party datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.4 Load dataset with statistics\n",
    "Dataset is ready for experiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   target  group  a1_x_signal_complexity  a1_x_signal_shannon_entropy  \\\n0     0.0    1.0                1.865568                     6.388020   \n1     0.0    1.0                1.812863                     6.507361   \n2     0.0    1.0                1.775775                     6.489806   \n3     0.0    1.0                1.912905                     6.422261   \n4     0.0    1.0                1.868826                     6.449559   \n\n   a1_x_signal_kurtosis  a1_x_signal_variation  a1_x_signal_hurst  \\\n0             -0.337526              -9.989303           0.626170   \n1             -0.329388              -8.479932           0.633813   \n2             -0.439591              -9.585973           0.625745   \n3             -0.364524              -9.033494           0.606942   \n4              0.017384              -8.482620           0.631058   \n\n   a1_x_signal_skew  a1_x_signal_activity  a1_x_signal_iqr  ...  \\\n0         -0.231906              0.519530         3.006134  ...   \n1          0.046480              0.519920         3.270674  ...   \n2          0.014204              0.531458         3.174478  ...   \n3         -0.145760              0.512090         2.982085  ...   \n4         -0.149621              0.526677         2.982085  ...   \n\n   a2_z_specter_iqr  a2_z_specter_zero_crossing  a2_z_specter_range  \\\n0        130.212247                         0.0          430.516204   \n1         79.932721                         0.0          339.669032   \n2         87.487539                         0.0          359.727237   \n3         78.688634                         0.0          353.579137   \n4         83.595954                         0.0          331.560162   \n\n   a2_z_specter_mean  a2_z_specter_petrosian_fd  a2_z_specter_higuchi_fd  \\\n0         121.609951                   1.024136                 1.709899   \n1         116.951076                   1.024806                 1.754620   \n2         126.969372                   1.022686                 1.718792   \n3         108.447712                   1.025371                 1.746161   \n4         112.269206                   1.024240                 1.762398   \n\n   a2_z_specter_crest_factor  a2_z_specter_energy  a2_z_specter_std  \\\n0                   2.865578         2.261059e+07         88.439848   \n1                   2.630547         1.683235e+07         56.167537   \n2                   2.593399         1.971760e+07         59.969811   \n3                   2.880197         1.547513e+07         60.944452   \n4                   2.665190         1.596652e+07         57.984006   \n\n   a2_z_specter_sample_entropy  \n0                     2.754299  \n1                     2.881832  \n2                     2.874073  \n3                     2.780298  \n4                     2.852191  \n\n[5 rows x 206 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>group</th>\n      <th>a1_x_signal_complexity</th>\n      <th>a1_x_signal_shannon_entropy</th>\n      <th>a1_x_signal_kurtosis</th>\n      <th>a1_x_signal_variation</th>\n      <th>a1_x_signal_hurst</th>\n      <th>a1_x_signal_skew</th>\n      <th>a1_x_signal_activity</th>\n      <th>a1_x_signal_iqr</th>\n      <th>...</th>\n      <th>a2_z_specter_iqr</th>\n      <th>a2_z_specter_zero_crossing</th>\n      <th>a2_z_specter_range</th>\n      <th>a2_z_specter_mean</th>\n      <th>a2_z_specter_petrosian_fd</th>\n      <th>a2_z_specter_higuchi_fd</th>\n      <th>a2_z_specter_crest_factor</th>\n      <th>a2_z_specter_energy</th>\n      <th>a2_z_specter_std</th>\n      <th>a2_z_specter_sample_entropy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.865568</td>\n      <td>6.388020</td>\n      <td>-0.337526</td>\n      <td>-9.989303</td>\n      <td>0.626170</td>\n      <td>-0.231906</td>\n      <td>0.519530</td>\n      <td>3.006134</td>\n      <td>...</td>\n      <td>130.212247</td>\n      <td>0.0</td>\n      <td>430.516204</td>\n      <td>121.609951</td>\n      <td>1.024136</td>\n      <td>1.709899</td>\n      <td>2.865578</td>\n      <td>2.261059e+07</td>\n      <td>88.439848</td>\n      <td>2.754299</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.812863</td>\n      <td>6.507361</td>\n      <td>-0.329388</td>\n      <td>-8.479932</td>\n      <td>0.633813</td>\n      <td>0.046480</td>\n      <td>0.519920</td>\n      <td>3.270674</td>\n      <td>...</td>\n      <td>79.932721</td>\n      <td>0.0</td>\n      <td>339.669032</td>\n      <td>116.951076</td>\n      <td>1.024806</td>\n      <td>1.754620</td>\n      <td>2.630547</td>\n      <td>1.683235e+07</td>\n      <td>56.167537</td>\n      <td>2.881832</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.775775</td>\n      <td>6.489806</td>\n      <td>-0.439591</td>\n      <td>-9.585973</td>\n      <td>0.625745</td>\n      <td>0.014204</td>\n      <td>0.531458</td>\n      <td>3.174478</td>\n      <td>...</td>\n      <td>87.487539</td>\n      <td>0.0</td>\n      <td>359.727237</td>\n      <td>126.969372</td>\n      <td>1.022686</td>\n      <td>1.718792</td>\n      <td>2.593399</td>\n      <td>1.971760e+07</td>\n      <td>59.969811</td>\n      <td>2.874073</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.912905</td>\n      <td>6.422261</td>\n      <td>-0.364524</td>\n      <td>-9.033494</td>\n      <td>0.606942</td>\n      <td>-0.145760</td>\n      <td>0.512090</td>\n      <td>2.982085</td>\n      <td>...</td>\n      <td>78.688634</td>\n      <td>0.0</td>\n      <td>353.579137</td>\n      <td>108.447712</td>\n      <td>1.025371</td>\n      <td>1.746161</td>\n      <td>2.880197</td>\n      <td>1.547513e+07</td>\n      <td>60.944452</td>\n      <td>2.780298</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.868826</td>\n      <td>6.449559</td>\n      <td>0.017384</td>\n      <td>-8.482620</td>\n      <td>0.631058</td>\n      <td>-0.149621</td>\n      <td>0.526677</td>\n      <td>2.982085</td>\n      <td>...</td>\n      <td>83.595954</td>\n      <td>0.0</td>\n      <td>331.560162</td>\n      <td>112.269206</td>\n      <td>1.024240</td>\n      <td>1.762398</td>\n      <td>2.665190</td>\n      <td>1.596652e+07</td>\n      <td>57.984006</td>\n      <td>2.852191</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 206 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_data = pd.read_csv(os.path.join(own_data_path, 'processed_full_signal_specter1000_noscale.csv'), delimiter=',')\n",
    "prepared_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "## 1.2 Signals and classes datasets join\n",
    "Use to combine our datasets into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets_map = dict(zip(classes_dataset['bearing_id'], classes_dataset['status']))\n",
    "targets_vector = signals_dataset['bearing_2_id'].map(targets_map)\n",
    "joined_dataset = signals_dataset.copy()\n",
    "joined_dataset.insert(loc=0, column='target', value=targets_vector)\n",
    "joined_dataset.to_csv(os.path.join(own_data_path, 'bearings.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "## 1.3 Convert third-party data files to our standard dataframe view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cesar_1_path = os.path.join(third_party_data_path, 'Bearings_cesar_1')\n",
    "cesar_1 = converter.Converter.cesar_convert(cesar_1_path)\n",
    "\n",
    "cesar_2_path = os.path.join(third_party_data_path, 'Bearings_cesar_1')\n",
    "cesar_2 = converter.Converter.cesar_convert(cesar_2_path)\n",
    "\n",
    "luigi_path = os.path.join(third_party_data_path, 'Bearings_luigi')\n",
    "luigi = converter.Converter.luigi_convert(luigi_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "## 1.4 Split datasets\n",
    "Split datasets on chunks and evaluate set of statistical features for each chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%% time\n",
    "\n",
    "# stats = ['mean', 'std']  # You can directly input statistics names\n",
    "stats = iterators.Stats.get_keys()  # If you need to calculate all supported statistics\n",
    "splitter = splitter.Splitter(use_signal=True, use_specter=True, specter_threshold=1000, stats=stats)\n",
    "prepared_data = splitter.split_dataset(joined_dataset, stable_area=(10, 19), splits_number=10,\n",
    "                                       signal_data_columns=['a1_x', 'a1_y', 'a1_z', 'a2_x', 'a2_y', 'a2_z'])\n",
    "print(f\"features number: {prepared_data.shape[1]-2}\")\n",
    "print(f\"examples number: {prepared_data.shape[0]}\")\n",
    "print(prepared_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2 Run ML experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.2 Run cross-validation\n",
    "As an example, cross-validation with grouped overlap resampling launched here over logistic regression, SVC and random forest classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from source.processes import Shuffler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "(1120, 204)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = prepared_data.drop(columns=['target', 'group']).values\n",
    "y = prepared_data['target'].values\n",
    "groups = prepared_data['group'].values\n",
    "\n",
    "LR_params = {'C': 10000}\n",
    "logit = LogisticRegression()\n",
    "logit.set_params(**LR_params)\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "cv = Shuffler.OverlapGroupCV(train_size=0.63, n_repeats=100).split(X_scaled, y, groups)\n",
    "\n",
    "scores = iterators.Metrics.get_scorers_dict()  # Get dict of scores in format required by cross_validate() scoring field\n",
    "\n",
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fit_time', 'score_time', 'test_TNR', 'test_TPR', 'test_accuracy', 'test_f1', 'test_precision', 'test_recall']\n",
      "Wall time: 4.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_results = cross_validate(logit, X_scaled, y, cv=cv, scoring=scores, groups=groups)\n",
    "print(sorted(cv_results.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 Run GridSearch\n",
    "GridSearch for Logistic Regression tuning with bootstrapped samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from source.processes import Shuffler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "X = prepared_data.drop(columns=['target', 'group']).values\n",
    "y = prepared_data['target'].values\n",
    "groups = prepared_data['group'].values\n",
    "\n",
    "logit = LogisticRegression()\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "cv = Shuffler.OverlapGroupCV(train_size=0.63, n_repeats=100).split(X_scaled, y, groups)\n",
    "grid = {'C': np.logspace(-3, 4, 8)}\n",
    "gscv = GridSearchCV(logit, grid, scoring='f1', cv=cv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass groups=[  1.   1.   1. ... 112. 112. 112.] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10000.0}\n",
      "0.8749091756161085\n",
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gscv.fit(X_scaled, y, groups)\n",
    "print(gscv.best_params_)\n",
    "print(gscv.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 Results postprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 extract bootstrap scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.1 extract CV scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9708809523809525, 'precision': 0.959074065252024, 'recall': 0.7944, 'f1': 0.8617638423433636, 'TPR': 0.7944, 'TNR': 0.9947297297297295}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "cv_scores_names = [f'test_{score}' for score in scores.keys()]\n",
    "cv_scores ={re.sub(\"test_\",\"\", k):list(cv_results[k]) for k in cv_scores_names}\n",
    "mean_scores = { k:np.mean(cv_scores[k]) for k in cv_scores.keys()}\n",
    "print(mean_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Save experiment data to data model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2.1 Save cross-validation results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from source.datamodels.datamodels import BootstrapResults\n",
    "from source.datamodels.iterators import Axes, Stats\n",
    "\n",
    "result = BootstrapResults(\n",
    "    run_label = \"test cv run\",\n",
    "    model_name = \"LR\",\n",
    "    hyperparameters = LR_params,\n",
    "    use_signal = True,\n",
    "    use_specter = True,\n",
    "    specter_threshold = 1000,\n",
    "    axes = Axes.get_keys(),\n",
    "    stats = Stats.get_keys(),\n",
    "    predictions = None,\n",
    "    scores = mean_scores,\n",
    "    resampling_number = 100,\n",
    "    bootstrap_scores = cv_scores\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "09a5e7c8b183e7b2d0a3e79941b92934b636b4d366df9a66eaddd71cb8199dab"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}