{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from source.preprocessing import splitter, converter\n",
    "from source.datamodels import iterators\n",
    "from source.utils import get_project_root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1 Preprocessing\n",
    "load datasets, convert third-party data files to our format etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.1 Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "root = get_project_root()\n",
    "config = configparser.ConfigParser()\n",
    "config.read(os.path.join(root, \"userconfig.ini\"))\n",
    "\n",
    "own_data_path = config['Path']['own_data_path']\n",
    "third_party_data_path = config['Path']['third_party_data_path']\n",
    "Cesar1_path = config['Path']['Cesar1_path']\n",
    "\n",
    "images_path = config['Path']['images_path']\n",
    "public_images_path = config['Path']['public_images_path']\n",
    "\n",
    "tables_path = config['Path']['tables_path']\n",
    "public_tables_path = config['Path']['public_tables_path']\n",
    "\n",
    "bootstrap_jsons_path = config['Path']['bootstrap_jsons_path']\n",
    "single_jsons_path = config['Path']['single_jsons_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.1.1 Load our initial datasets\n",
    "Datasets obtained from our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "signals_dataset = pd.read_csv(os.path.join(root, own_data_path, 'bearing_signals.csv'))\n",
    "classes_dataset = pd.read_csv(os.path.join(root, own_data_path, 'bearing_classes.csv'), delimiter=';', skiprows=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.2 Load our joined datasets\n",
    "Datasets obtained from our experiments with joined target column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0  target  experiment_id  bearing_1_id  bearing_2_id  timestamp  \\\n0           0       0              1             0             1   0.000000   \n1           1       0              1             0             1   0.000333   \n2           2       0              1             0             1   0.000667   \n3           3       0              1             0             1   0.001000   \n4           4       0              1             0             1   0.001333   \n\n       a1_x      a1_y      a1_z      a2_x      a2_y      a2_z  rpm   hz  \\\n0  0.113269  0.149706 -0.110275 -0.186030  0.194450  0.454299  0.0  0.0   \n1 -0.367713 -0.228832  0.177821  0.285992  0.002226 -0.043930  0.0  0.0   \n2  0.113269  0.149706 -0.398371 -0.091625  0.002226  0.454299  0.0  0.0   \n3 -0.175320 -0.228832 -0.110275  0.285992  0.002226  0.255007  0.0  0.0   \n4 -0.079124  0.055072 -0.110275  0.191588  0.002226  0.255007  0.0  0.0   \n\n          w  \n0  0.000006  \n1  0.000243  \n2  0.000369  \n3  0.000520  \n4  0.000175  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>target</th>\n      <th>experiment_id</th>\n      <th>bearing_1_id</th>\n      <th>bearing_2_id</th>\n      <th>timestamp</th>\n      <th>a1_x</th>\n      <th>a1_y</th>\n      <th>a1_z</th>\n      <th>a2_x</th>\n      <th>a2_y</th>\n      <th>a2_z</th>\n      <th>rpm</th>\n      <th>hz</th>\n      <th>w</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.113269</td>\n      <td>0.149706</td>\n      <td>-0.110275</td>\n      <td>-0.186030</td>\n      <td>0.194450</td>\n      <td>0.454299</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000006</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.000333</td>\n      <td>-0.367713</td>\n      <td>-0.228832</td>\n      <td>0.177821</td>\n      <td>0.285992</td>\n      <td>0.002226</td>\n      <td>-0.043930</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000243</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.000667</td>\n      <td>0.113269</td>\n      <td>0.149706</td>\n      <td>-0.398371</td>\n      <td>-0.091625</td>\n      <td>0.002226</td>\n      <td>0.454299</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000369</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.001000</td>\n      <td>-0.175320</td>\n      <td>-0.228832</td>\n      <td>-0.110275</td>\n      <td>0.285992</td>\n      <td>0.002226</td>\n      <td>0.255007</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000520</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.001333</td>\n      <td>-0.079124</td>\n      <td>0.055072</td>\n      <td>-0.110275</td>\n      <td>0.191588</td>\n      <td>0.002226</td>\n      <td>0.255007</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000175</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset = pd.read_csv(os.path.join(root, own_data_path, 'bearings.csv'), delimiter=',')\n",
    "full_dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.1.3 Load third-party datasets\n",
    "Load third-party datasets, converted to our standard view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   target      a1_y      a2_y  rpm  experiment_id  timestamp\n0       1  1.937934  1.954861  200              1   0.000000\n1       1  1.937547  1.954629  200              1   0.000025\n2       1  1.937166  1.954989  200              1   0.000050\n3       1  1.937594  1.955540  200              1   0.000075\n4       1  1.938502  1.955792  200              1   0.000100",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>a1_y</th>\n      <th>a2_y</th>\n      <th>rpm</th>\n      <th>experiment_id</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1.937934</td>\n      <td>1.954861</td>\n      <td>200</td>\n      <td>1</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1.937547</td>\n      <td>1.954629</td>\n      <td>200</td>\n      <td>1</td>\n      <td>0.000025</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1.937166</td>\n      <td>1.954989</td>\n      <td>200</td>\n      <td>1</td>\n      <td>0.000050</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1.937594</td>\n      <td>1.955540</td>\n      <td>200</td>\n      <td>1</td>\n      <td>0.000075</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1.938502</td>\n      <td>1.955792</td>\n      <td>200</td>\n      <td>1</td>\n      <td>0.000100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset = pd.read_csv(os.path.join(root, third_party_data_path, 'N1 Cesar Ricardo', 'csv', 'bearings.csv'), delimiter=',')\n",
    "full_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.4 Load dataset with statistics\n",
    "Dataset is ready for experiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   target  group  a1_x_signal_complexity  a1_x_signal_shannon_entropy  \\\n0     0.0    1.0                1.865568                     6.388020   \n1     0.0    1.0                1.812863                     6.507361   \n2     0.0    1.0                1.775775                     6.489806   \n3     0.0    1.0                1.912905                     6.422261   \n4     0.0    1.0                1.868826                     6.449559   \n\n   a1_x_signal_kurtosis  a1_x_signal_variation  a1_x_signal_hurst  \\\n0             -0.337526              -9.989303           0.626170   \n1             -0.329388              -8.479932           0.633813   \n2             -0.439591              -9.585973           0.625745   \n3             -0.364524              -9.033494           0.606942   \n4              0.017384              -8.482620           0.631058   \n\n   a1_x_signal_skew  a1_x_signal_activity  a1_x_signal_iqr  ...  \\\n0         -0.231906              0.519530         3.006134  ...   \n1          0.046480              0.519920         3.270674  ...   \n2          0.014204              0.531458         3.174478  ...   \n3         -0.145760              0.512090         2.982085  ...   \n4         -0.149621              0.526677         2.982085  ...   \n\n   a2_z_specter_iqr  a2_z_specter_zero_crossing  a2_z_specter_range  \\\n0        130.212247                         0.0          430.516204   \n1         79.932721                         0.0          339.669032   \n2         87.487539                         0.0          359.727237   \n3         78.688634                         0.0          353.579137   \n4         83.595954                         0.0          331.560162   \n\n   a2_z_specter_mean  a2_z_specter_petrosian_fd  a2_z_specter_higuchi_fd  \\\n0         121.609951                   1.024136                 1.709899   \n1         116.951076                   1.024806                 1.754620   \n2         126.969372                   1.022686                 1.718792   \n3         108.447712                   1.025371                 1.746161   \n4         112.269206                   1.024240                 1.762398   \n\n   a2_z_specter_crest_factor  a2_z_specter_energy  a2_z_specter_std  \\\n0                   2.865578         2.261059e+07         88.439848   \n1                   2.630547         1.683235e+07         56.167537   \n2                   2.593399         1.971760e+07         59.969811   \n3                   2.880197         1.547513e+07         60.944452   \n4                   2.665190         1.596652e+07         57.984006   \n\n   a2_z_specter_sample_entropy  \n0                     2.754299  \n1                     2.881832  \n2                     2.874073  \n3                     2.780298  \n4                     2.852191  \n\n[5 rows x 206 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>group</th>\n      <th>a1_x_signal_complexity</th>\n      <th>a1_x_signal_shannon_entropy</th>\n      <th>a1_x_signal_kurtosis</th>\n      <th>a1_x_signal_variation</th>\n      <th>a1_x_signal_hurst</th>\n      <th>a1_x_signal_skew</th>\n      <th>a1_x_signal_activity</th>\n      <th>a1_x_signal_iqr</th>\n      <th>...</th>\n      <th>a2_z_specter_iqr</th>\n      <th>a2_z_specter_zero_crossing</th>\n      <th>a2_z_specter_range</th>\n      <th>a2_z_specter_mean</th>\n      <th>a2_z_specter_petrosian_fd</th>\n      <th>a2_z_specter_higuchi_fd</th>\n      <th>a2_z_specter_crest_factor</th>\n      <th>a2_z_specter_energy</th>\n      <th>a2_z_specter_std</th>\n      <th>a2_z_specter_sample_entropy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.865568</td>\n      <td>6.388020</td>\n      <td>-0.337526</td>\n      <td>-9.989303</td>\n      <td>0.626170</td>\n      <td>-0.231906</td>\n      <td>0.519530</td>\n      <td>3.006134</td>\n      <td>...</td>\n      <td>130.212247</td>\n      <td>0.0</td>\n      <td>430.516204</td>\n      <td>121.609951</td>\n      <td>1.024136</td>\n      <td>1.709899</td>\n      <td>2.865578</td>\n      <td>2.261059e+07</td>\n      <td>88.439848</td>\n      <td>2.754299</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.812863</td>\n      <td>6.507361</td>\n      <td>-0.329388</td>\n      <td>-8.479932</td>\n      <td>0.633813</td>\n      <td>0.046480</td>\n      <td>0.519920</td>\n      <td>3.270674</td>\n      <td>...</td>\n      <td>79.932721</td>\n      <td>0.0</td>\n      <td>339.669032</td>\n      <td>116.951076</td>\n      <td>1.024806</td>\n      <td>1.754620</td>\n      <td>2.630547</td>\n      <td>1.683235e+07</td>\n      <td>56.167537</td>\n      <td>2.881832</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.775775</td>\n      <td>6.489806</td>\n      <td>-0.439591</td>\n      <td>-9.585973</td>\n      <td>0.625745</td>\n      <td>0.014204</td>\n      <td>0.531458</td>\n      <td>3.174478</td>\n      <td>...</td>\n      <td>87.487539</td>\n      <td>0.0</td>\n      <td>359.727237</td>\n      <td>126.969372</td>\n      <td>1.022686</td>\n      <td>1.718792</td>\n      <td>2.593399</td>\n      <td>1.971760e+07</td>\n      <td>59.969811</td>\n      <td>2.874073</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.912905</td>\n      <td>6.422261</td>\n      <td>-0.364524</td>\n      <td>-9.033494</td>\n      <td>0.606942</td>\n      <td>-0.145760</td>\n      <td>0.512090</td>\n      <td>2.982085</td>\n      <td>...</td>\n      <td>78.688634</td>\n      <td>0.0</td>\n      <td>353.579137</td>\n      <td>108.447712</td>\n      <td>1.025371</td>\n      <td>1.746161</td>\n      <td>2.880197</td>\n      <td>1.547513e+07</td>\n      <td>60.944452</td>\n      <td>2.780298</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.868826</td>\n      <td>6.449559</td>\n      <td>0.017384</td>\n      <td>-8.482620</td>\n      <td>0.631058</td>\n      <td>-0.149621</td>\n      <td>0.526677</td>\n      <td>2.982085</td>\n      <td>...</td>\n      <td>83.595954</td>\n      <td>0.0</td>\n      <td>331.560162</td>\n      <td>112.269206</td>\n      <td>1.024240</td>\n      <td>1.762398</td>\n      <td>2.665190</td>\n      <td>1.596652e+07</td>\n      <td>57.984006</td>\n      <td>2.852191</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 206 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_data = pd.read_csv(os.path.join(root, own_data_path, 'processed_full_signal_specter1000_noscale.csv'), delimiter=',')  # our experiment\n",
    "# prepared_data = pd.read_csv(os.path.join(root, third_party_data_path, 'N1 Cesar Ricardo', 'csv',\n",
    "#                                          'processed_full_signal_specter1000_noscale.csv'), delimiter=',')  # third-party dataset\n",
    "prepared_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "## 1.2 Signals and classes datasets join\n",
    "Use to combine our datasets into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets_map = dict(zip(classes_dataset['bearing_id'], classes_dataset['status']))\n",
    "targets_vector = signals_dataset['bearing_2_id'].map(targets_map)\n",
    "joined_dataset = signals_dataset.copy()\n",
    "joined_dataset.insert(loc=0, column='target', value=targets_vector)\n",
    "joined_dataset.to_csv(os.path.join(own_data_path, 'bearings.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "## 1.3 Convert third-party data files to our standard dataframe view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cesar_1_path = os.path.join(root, third_party_data_path, 'N1 Cesar Ricardo')\n",
    "cesar_1 = converter.Converter.cesar_convert(cesar_1_path)\n",
    "cesar_1.head()\n",
    "\n",
    "# cesar_2_path = os.path.join(third_party_data_path, 'Bearings_cesar_1')\n",
    "# cesar_2 = converter.Converter.cesar_convert(cesar_2_path)\n",
    "\n",
    "# luigi_path = os.path.join(third_party_data_path, 'Bearings_luigi')\n",
    "# luigi = converter.Converter.luigi_convert(luigi_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "## 1.4 Split datasets\n",
    "Split datasets on chunks and evaluate set of statistical features for each chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4.1 Split our dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features number: 18\n",
      "examples number: 1120\n",
      "Wall time: 11.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "   target  group  a1_x_signal_mean  a1_x_signal_std  a1_x_signal_skew  \\\n0     0.0    1.0         -0.091416         0.168345         -0.094233   \n1     0.0    1.0         -0.085323         0.168466         -0.046775   \n2     0.0    1.0         -0.093981         0.165922         -0.016693   \n3     0.0    1.0         -0.088530         0.169049         -0.038873   \n4     0.0    1.0         -0.090133         0.166901         -0.093073   \n\n   a1_y_signal_mean  a1_y_signal_std  a1_y_signal_skew  a1_z_signal_mean  \\\n0          0.014905         0.164634         -0.139448         -0.105153   \n1          0.019847         0.166212         -0.140761         -0.120945   \n2          0.020267         0.163950         -0.211511         -0.113903   \n3          0.017533         0.167378         -0.247919         -0.104727   \n4          0.019952         0.169524         -0.157850         -0.114650   \n\n   a1_z_signal_std  a1_z_signal_skew  a2_x_signal_mean  a2_x_signal_std  \\\n0         0.177636         -0.188695          0.149840         0.160024   \n1         0.177100         -0.154561          0.146274         0.159796   \n2         0.178650         -0.166532          0.151308         0.161691   \n3         0.177623         -0.181540          0.150784         0.160421   \n4         0.180942         -0.198373          0.152462         0.162736   \n\n   a2_x_signal_skew  a2_y_signal_mean  a2_y_signal_std  a2_y_signal_skew  \\\n0         -0.353922          0.039176         0.165201         -0.329476   \n1         -0.322403          0.032982         0.164606         -0.325526   \n2         -0.317274          0.044943         0.163114         -0.338985   \n3         -0.356063          0.038535         0.164410         -0.367420   \n4         -0.415544          0.037467         0.161812         -0.335397   \n\n   a2_z_signal_mean  a2_z_signal_std  a2_z_signal_skew  \n0          0.195220         0.179240         -0.217640  \n1          0.191012         0.181040         -0.241943  \n2          0.190459         0.181786         -0.204486  \n3          0.186584         0.184207         -0.199939  \n4          0.190902         0.180665         -0.228084  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>group</th>\n      <th>a1_x_signal_mean</th>\n      <th>a1_x_signal_std</th>\n      <th>a1_x_signal_skew</th>\n      <th>a1_y_signal_mean</th>\n      <th>a1_y_signal_std</th>\n      <th>a1_y_signal_skew</th>\n      <th>a1_z_signal_mean</th>\n      <th>a1_z_signal_std</th>\n      <th>a1_z_signal_skew</th>\n      <th>a2_x_signal_mean</th>\n      <th>a2_x_signal_std</th>\n      <th>a2_x_signal_skew</th>\n      <th>a2_y_signal_mean</th>\n      <th>a2_y_signal_std</th>\n      <th>a2_y_signal_skew</th>\n      <th>a2_z_signal_mean</th>\n      <th>a2_z_signal_std</th>\n      <th>a2_z_signal_skew</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-0.091416</td>\n      <td>0.168345</td>\n      <td>-0.094233</td>\n      <td>0.014905</td>\n      <td>0.164634</td>\n      <td>-0.139448</td>\n      <td>-0.105153</td>\n      <td>0.177636</td>\n      <td>-0.188695</td>\n      <td>0.149840</td>\n      <td>0.160024</td>\n      <td>-0.353922</td>\n      <td>0.039176</td>\n      <td>0.165201</td>\n      <td>-0.329476</td>\n      <td>0.195220</td>\n      <td>0.179240</td>\n      <td>-0.217640</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-0.085323</td>\n      <td>0.168466</td>\n      <td>-0.046775</td>\n      <td>0.019847</td>\n      <td>0.166212</td>\n      <td>-0.140761</td>\n      <td>-0.120945</td>\n      <td>0.177100</td>\n      <td>-0.154561</td>\n      <td>0.146274</td>\n      <td>0.159796</td>\n      <td>-0.322403</td>\n      <td>0.032982</td>\n      <td>0.164606</td>\n      <td>-0.325526</td>\n      <td>0.191012</td>\n      <td>0.181040</td>\n      <td>-0.241943</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-0.093981</td>\n      <td>0.165922</td>\n      <td>-0.016693</td>\n      <td>0.020267</td>\n      <td>0.163950</td>\n      <td>-0.211511</td>\n      <td>-0.113903</td>\n      <td>0.178650</td>\n      <td>-0.166532</td>\n      <td>0.151308</td>\n      <td>0.161691</td>\n      <td>-0.317274</td>\n      <td>0.044943</td>\n      <td>0.163114</td>\n      <td>-0.338985</td>\n      <td>0.190459</td>\n      <td>0.181786</td>\n      <td>-0.204486</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-0.088530</td>\n      <td>0.169049</td>\n      <td>-0.038873</td>\n      <td>0.017533</td>\n      <td>0.167378</td>\n      <td>-0.247919</td>\n      <td>-0.104727</td>\n      <td>0.177623</td>\n      <td>-0.181540</td>\n      <td>0.150784</td>\n      <td>0.160421</td>\n      <td>-0.356063</td>\n      <td>0.038535</td>\n      <td>0.164410</td>\n      <td>-0.367420</td>\n      <td>0.186584</td>\n      <td>0.184207</td>\n      <td>-0.199939</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-0.090133</td>\n      <td>0.166901</td>\n      <td>-0.093073</td>\n      <td>0.019952</td>\n      <td>0.169524</td>\n      <td>-0.157850</td>\n      <td>-0.114650</td>\n      <td>0.180942</td>\n      <td>-0.198373</td>\n      <td>0.152462</td>\n      <td>0.162736</td>\n      <td>-0.415544</td>\n      <td>0.037467</td>\n      <td>0.161812</td>\n      <td>-0.335397</td>\n      <td>0.190902</td>\n      <td>0.180665</td>\n      <td>-0.228084</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stats = ['mean', 'std', 'skew']  # You can directly input statistics names\n",
    "# stats = iterators.Stats.get_keys()  # Use Stats.get_keys() if you need to calculate all supported statistics\n",
    "splitter_processor = splitter.Splitter(use_signal=True, use_specter=False, specter_threshold=1000, stats=stats)\n",
    "prepared_data = splitter_processor.split_dataset(full_dataset, stable_area=[(0, 3)], splits_number=10,\n",
    "                                                 signal_data_columns=['a1_x', 'a1_y', 'a1_z', 'a2_x', 'a2_y', 'a2_z'])\n",
    "print(f\"features number: {prepared_data.shape[1]-2}\")\n",
    "print(f\"examples number: {prepared_data.shape[0]}\")\n",
    "prepared_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4.2 Split third-party dataset\n",
    "For datasets created by César Ricardo Soto-Ocampo et al. there is a1_y and a2_y columns. For this example we use stable timezone from 0 to 3 seconds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "joined_dataset = cesar_1\n",
    "stats = iterators.Stats.get_keys()\n",
    "stats = [stat for stat in stats if stat not in ['mean', 'std', 'variation']]\n",
    "splitter_processor = splitter.Splitter(use_signal=True, use_specter=True, specter_threshold=1000, stats=stats, scaler=StandardScaler)\n",
    "prepared_data = splitter_processor.split_dataset(joined_dataset, stable_area=[(0, 3)], splits_number=10, signal_data_columns=['a1_y', 'a2_y'])\n",
    "print(f\"features number: {prepared_data.shape[1]-2}\")\n",
    "print(f\"examples number: {prepared_data.shape[0]}\")\n",
    "prepared_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2 Run ML experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.1 Run cross-validation\n",
    "As an example, cross-validation with grouped overlap resampling launched here over logistic regression, SVC and random forest classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.2.1 Initialize experiment workflow and estimators"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from source.processes import Shuffler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(n_estimators=200)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_params = {'C': 10}\n",
    "logit = LogisticRegression()\n",
    "logit.set_params(**LR_params)\n",
    "\n",
    "SVC_params = {'C': 10}\n",
    "svc = SVC()\n",
    "svc.set_params(**SVC_params)\n",
    "\n",
    "RFC_params = {'n_estimators': 200}\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.set_params(**RFC_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(1120, 204)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = prepared_data.drop(columns=['target', 'group']).values\n",
    "y = prepared_data['target'].values\n",
    "groups = prepared_data['group'].values\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "scores = iterators.Metrics.get_scorers_dict()  # Get dict of scores in format required by cross_validate() scoring field\n",
    "\n",
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2.2 run cross-validations for each estimator\n",
    "We run 100 fits for each estimator in this example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression mean F1 score: 0.841052024168488\n",
      "Wall time: 6.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = Shuffler.OverlapGroupCV(train_size=0.63, n_repeats=100).split(X_scaled, y, groups)\n",
    "logit_cv_results = cross_validate(logit, X_scaled, y, cv=cv, scoring=scores, groups=groups)\n",
    "print(f\"Logistic regression mean F1 score: {np.mean(logit_cv_results['test_f1'])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC mean F1 score: 0.7445571254312032\n",
      "Wall time: 5.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = Shuffler.OverlapGroupCV(train_size=0.63, n_repeats=100).split(X_scaled, y, groups)\n",
    "svc_cv_results = cross_validate(svc, X_scaled, y, cv=cv, scoring=scores, groups=groups)\n",
    "print(f\"SVC mean F1 score: {np.mean(svc_cv_results['test_f1'])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest mean F1 score: 0.7327410602124919\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = Shuffler.OverlapGroupCV(train_size=0.63, n_repeats=100).split(X_scaled, y, groups)\n",
    "rfc_cv_results = cross_validate(rfc, X_scaled, y, cv=cv, scoring=scores, groups=groups)\n",
    "print(f\"Random forest mean F1 score: {np.mean(rfc_cv_results['test_f1'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 Run GridSearch\n",
    "GridSearch for Logistic Regression tuning with bootstrapped samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from source.processes import Shuffler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "X = prepared_data.drop(columns=['target', 'group']).values\n",
    "y = prepared_data['target'].values\n",
    "groups = prepared_data['group'].values\n",
    "\n",
    "logit = LogisticRegression()\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "cv = Shuffler.OverlapGroupCV(train_size=0.63, n_repeats=100).split(X_scaled, y, groups)\n",
    "grid = {'C': np.logspace(-3, 4, 8)}\n",
    "gscv = GridSearchCV(logit, grid, scoring='f1', cv=cv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass groups=[  1.   1.   1. ... 112. 112. 112.] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10000.0}\n",
      "0.8749091756161085\n",
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gscv.fit(X_scaled, y, groups)\n",
    "print(gscv.best_params_)\n",
    "print(gscv.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 Results postprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 extract bootstrap scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.1 extract CV scores\n",
    "There we extract scores, obtained in stage 2.2.2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR mean scores: {'accuracy': 0.9672857142857141, 'precision': 0.9600499700732599, 'recall': 0.7603999999999997, 'f1': 0.841052024168488, 'TPR': 0.7603999999999997, 'TNR': 0.9952432432432431}\n",
      "SVC mean scores: {'accuracy': 0.9509047619047619, 'precision': 0.9424801908679588, 'recall': 0.6327999999999999, 'f1': 0.7445571254312032, 'TPR': 0.6327999999999999, 'TNR': 0.9938918918918919}\n",
      "RFC mean scores: {'accuracy': 0.9518095238095239, 'precision': 0.9979512288786482, 'recall': 0.596, 'f1': 0.7327410602124919, 'TPR': 0.596, 'TNR': 0.9998918918918919}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "cv_scores_names = [f'test_{score}' for score in scores.keys()]\n",
    "\n",
    "logit_cv_scores ={re.sub(\"test_\",\"\", k):list(logit_cv_results[k]) for k in cv_scores_names}\n",
    "logit_mean_scores = { k:np.mean(logit_cv_scores[k]) for k in logit_cv_scores.keys()}\n",
    "print(f\"LR mean scores: {logit_mean_scores}\")\n",
    "\n",
    "svc_cv_scores ={re.sub(\"test_\",\"\", k):list(svc_cv_results[k]) for k in cv_scores_names}\n",
    "svc_mean_scores = { k:np.mean(svc_cv_scores[k]) for k in svc_cv_scores.keys()}\n",
    "print(f\"SVC mean scores: {svc_mean_scores}\")\n",
    "\n",
    "rfc_cv_scores ={re.sub(\"test_\",\"\", k):list(rfc_cv_results[k]) for k in cv_scores_names}\n",
    "rfc_mean_scores = { k:np.mean(rfc_cv_scores[k]) for k in rfc_cv_scores.keys()}\n",
    "print(f\"RFC mean scores: {rfc_mean_scores}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Save experiment data to data model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2.1 Save cross-validation results\n",
    "We save cv results as BootstrapResults instances to further serialization (stage 3.2.3) and ML experiment tracking tables creation (stage 3.2.4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from source.datamodels.datamodels import BootstrapResults\n",
    "from source.datamodels.iterators import Axes, Stats\n",
    "\n",
    "logit_result_obj = BootstrapResults(\n",
    "    run_label = \"test cv run\",\n",
    "    model_name = \"LR\",\n",
    "    hyperparameters = LR_params,\n",
    "    use_signal = True,\n",
    "    use_specter = True,\n",
    "    specter_threshold = 1000,\n",
    "    axes = Axes.get_keys(),\n",
    "    stats = Stats.get_keys(),\n",
    "    predictions = None,\n",
    "    scores = logit_mean_scores,\n",
    "    resampling_number = 100,\n",
    "    bootstrap_scores = logit_cv_scores\n",
    ")\n",
    "\n",
    "svc_result_obj = BootstrapResults(\n",
    "    run_label = \"test cv run\",\n",
    "    model_name = \"SVC\",\n",
    "    hyperparameters = SVC_params,\n",
    "    use_signal = True,\n",
    "    use_specter = True,\n",
    "    specter_threshold = 1000,\n",
    "    axes = Axes.get_keys(),\n",
    "    stats = Stats.get_keys(),\n",
    "    predictions = None,\n",
    "    scores = svc_mean_scores,\n",
    "    resampling_number = 100,\n",
    "    bootstrap_scores = svc_cv_scores\n",
    ")\n",
    "\n",
    "rfc_result_obj = BootstrapResults(\n",
    "    run_label = \"test cv run\",\n",
    "    model_name = \"RFC\",\n",
    "    hyperparameters = RFC_params,\n",
    "    use_signal = True,\n",
    "    use_specter = True,\n",
    "    specter_threshold = 1000,\n",
    "    axes = Axes.get_keys(),\n",
    "    stats = Stats.get_keys(),\n",
    "    predictions = None,\n",
    "    scores = rfc_mean_scores,\n",
    "    resampling_number = 100,\n",
    "    bootstrap_scores = rfc_cv_scores\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2.2 Plot results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from source.postprocessing.plotter import bar_plot\n",
    "\n",
    "bar_plot(results=[logit_mean_scores, rfc_mean_scores, svc_mean_scores], models=['LR', 'RF', 'SVM'], metrics=list(logit_mean_scores.keys()), plot_size=(8, 12), Title='Test CV mean scores', filename='test_cv_mean_scores.png', filepath=os.path.join(root, images_path))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2.3 Results serialization\n",
    "We serialize objects obtained in stage 3.2.1 for full reproducibility of experiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from source.postprocessing.mljson import serialize_results\n",
    "\n",
    "\n",
    "CV_results_path = os.path.join(root, bootstrap_jsons_path, \"CV\")\n",
    "ResultTablesPath = os.path.join(root, tables_path)\n",
    "results_objects=[logit_result_obj, svc_result_obj, rfc_result_obj]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "serialize_results(results=results_objects, filenames=['logit_test.json', 'svc_test.json', 'rfc_test.json'], filepath=CV_results_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2.4 Write results to Excel table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from source.postprocessing.mlcsv import generate_csv_from_results, create_readable_xlsx\n",
    "\n",
    "\n",
    "generate_csv_from_results(results_objects, csv_name='csv_test.csv', results_type=BootstrapResults, csv_path=ResultTablesPath)\n",
    "create_readable_xlsx(xlsx_name='xlsx_test.xlsx', csv_name='csv_test.csv', xlsx_path=ResultTablesPath, csv_path=ResultTablesPath)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "   experiment index    run_label model_name use_signal use_specter  \\\n0                 0  test cv run         LR        Yes         Yes   \n1                 1  test cv run        SVC        Yes         Yes   \n2                 2  test cv run        RFC        Yes         Yes   \n\n   specter_threshold  resampling_number Scores: accuracy Scores: precision  \\\n0               1000                100             0,97             0,958   \n1               1000                100             0,95             0,949   \n2               1000                100            0,955               1,0   \n\n  Scores: recall  ... Statistics: energy Statistics: hurst  \\\n0          0,788  ...                Yes               Yes   \n1          0,622  ...                Yes               Yes   \n2          0,624  ...                Yes               Yes   \n\n  Statistics: petrosian_fd Statistics: zero_crossing Statistics: higuchi_fd  \\\n0                      Yes                       Yes                    Yes   \n1                      Yes                       Yes                    Yes   \n2                      Yes                       Yes                    Yes   \n\n  Statistics: activity Statistics: complexity Statistics: crest_factor  \\\n0                  Yes                    Yes                      Yes   \n1                  Yes                    Yes                      Yes   \n2                  Yes                    Yes                      Yes   \n\n  Hyperparameters: C Hyperparameters: n_estimators  \n0               10,0                           NaN  \n1               10,0                           NaN  \n2                NaN                         200,0  \n\n[3 rows x 38 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>experiment index</th>\n      <th>run_label</th>\n      <th>model_name</th>\n      <th>use_signal</th>\n      <th>use_specter</th>\n      <th>specter_threshold</th>\n      <th>resampling_number</th>\n      <th>Scores: accuracy</th>\n      <th>Scores: precision</th>\n      <th>Scores: recall</th>\n      <th>...</th>\n      <th>Statistics: energy</th>\n      <th>Statistics: hurst</th>\n      <th>Statistics: petrosian_fd</th>\n      <th>Statistics: zero_crossing</th>\n      <th>Statistics: higuchi_fd</th>\n      <th>Statistics: activity</th>\n      <th>Statistics: complexity</th>\n      <th>Statistics: crest_factor</th>\n      <th>Hyperparameters: C</th>\n      <th>Hyperparameters: n_estimators</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>test cv run</td>\n      <td>LR</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>1000</td>\n      <td>100</td>\n      <td>0,97</td>\n      <td>0,958</td>\n      <td>0,788</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>10,0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>test cv run</td>\n      <td>SVC</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>1000</td>\n      <td>100</td>\n      <td>0,95</td>\n      <td>0,949</td>\n      <td>0,622</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>10,0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>test cv run</td>\n      <td>RFC</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>1000</td>\n      <td>100</td>\n      <td>0,955</td>\n      <td>1,0</td>\n      <td>0,624</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>NaN</td>\n      <td>200,0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 38 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.read_excel(os.path.join(root, tables_path, 'xlsx_test.xlsx'))\n",
    "table.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "09a5e7c8b183e7b2d0a3e79941b92934b636b4d366df9a66eaddd71cb8199dab"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}